{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.charting_tools import Charting\n",
    "from helpers.data_processing import add_ti\n",
    "from BookWorm import BookWorm, BinanceWrapper\n",
    "from PIL import Image\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "worm = BookWorm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candles = worm.historical_candles(start_time='January 1 2018', end_time='February 1 2018', api_wrapper=BinanceWrapper('5lJ0uGit9PuUxHka3hBWhPmsi7dWyxEwvEntUZFKmm0xfNz3VjHWi5WSr5W1VBJV',\n",
    "                                                      'BFWVs8ko7Cd4sjdQ9amGJTnToGWy9TbQWIjeorSCj23FGiwFaknzkgLPcrgWrxsw'), \n",
    "                  symbol='ETHBTC', interval='1m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "candles = worm.historical_candles(start_time='February 2 2018', end_time='March 1 2018', api_wrapper=BinanceWrapper('5lJ0uGit9PuUxHka3hBWhPmsi7dWyxEwvEntUZFKmm0xfNz3VjHWi5WSr5W1VBJV',\n",
    "                                                      'BFWVs8ko7Cd4sjdQ9amGJTnToGWy9TbQWIjeorSCj23FGiwFaknzkgLPcrgWrxsw'), \n",
    "                  symbol='ETHBTC', interval='1m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candles.to_csv('ethbtc_1yr.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "candles = pd.read_csv('ethbtc_1yr.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/Projects/FALKOR/helpers/data_processing.py:71: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[label] = ti_dict[label]\n"
     ]
    }
   ],
   "source": [
    "candles = add_ti(candles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_candles(df, num_rows=30, step=10):\n",
    "    \"\"\"Split a DataFrame of candlestick data into a list of smaller DataFrames each with num_rows rows\"\"\"\n",
    "    \n",
    "    slices = []\n",
    "    \n",
    "    for row_i in range(0, df.shape[0] - num_rows, step):\n",
    "        small_df = df.iloc[row_i:row_i+num_rows, :]\n",
    "        slices.append(small_df)\n",
    "        \n",
    "    return slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def price_returns(df, num_rows=30, num_into_fut=5, step=10):\n",
    "    labels = []\n",
    "    \n",
    "    for row_i in range(0, df.shape[0] - num_rows - num_into_fut, step):\n",
    "        # skip all iterations while row_i < num_rows since nothing yet to create a label for\n",
    "        if row_i <= num_rows: continue\n",
    "        \n",
    "        vf, vi = df['close'][row_i+num_into_fut], df['close'][row_i]\n",
    "        price_return = (vf - vi) / vi\n",
    "        labels.append(price_return)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_charts(candles_sliced, save_path):\n",
    "    \"\"\"Create a chart image for each in sliced_candles and return a list of paths to those images\"\"\"\n",
    "    from tqdm import tqdm_notebook as tqdm\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    \n",
    "    i = 0\n",
    "    paths_to_images = []\n",
    "    for small_df in tqdm(candles_sliced):\n",
    "        chart = Charting(small_df, 'time', 'close')\n",
    "        \n",
    "        path = save_path + 'chart_{}.png'.format(i)\n",
    "        chart.chart_to_image(path)\n",
    "        paths_to_images.append(path)\n",
    "        i += 1\n",
    "    return paths_to_images        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_to_images = create_charts(candles_sliced, \"images/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_to_images = [ 'images/chart_{}.png'.format(i) for i in range(len(candles_sliced)) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.open(paths_to_images[103])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'price_returns' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-4af59c99c431>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprice_returnz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprice_returns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'price_returns' is not defined"
     ]
    }
   ],
   "source": [
    "price_returnz = price_returns(candles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_series(ser):\n",
    "    return (ser-ser.min())/(ser.max()-ser.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36798, 11)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try: candles = candles.drop('time', axis=1).reset_index(drop=True)\n",
    "except: pass\n",
    "candles.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36798, 11)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candles = candles.apply(normalize_series, axis=0)\n",
    "candles.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split candles into 30 period and a label\n",
    "candles_sliced = split_candles(candles)\n",
    "# we need to remove candle slices without a label from candles_sliced\n",
    "candles_sliced = candles_sliced[len(candles_sliced)-len(price_returnz):]\n",
    "\n",
    "assert len(candles_sliced) == len(price_returnz)\n",
    "len(candles_sliced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>sma20</th>\n",
       "      <th>macd</th>\n",
       "      <th>obv</th>\n",
       "      <th>bb20_low</th>\n",
       "      <th>bb20_mid</th>\n",
       "      <th>bb20_up</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999972</td>\n",
       "      <td>0.030238</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.992558</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.997085</td>\n",
       "      <td>0.997032</td>\n",
       "      <td>0.999304</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.055791</td>\n",
       "      <td>0.999248</td>\n",
       "      <td>0.923749</td>\n",
       "      <td>0.994914</td>\n",
       "      <td>0.997594</td>\n",
       "      <td>0.999248</td>\n",
       "      <td>0.996815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.997114</td>\n",
       "      <td>0.996268</td>\n",
       "      <td>0.992994</td>\n",
       "      <td>0.997190</td>\n",
       "      <td>0.051974</td>\n",
       "      <td>0.998616</td>\n",
       "      <td>0.852897</td>\n",
       "      <td>0.992716</td>\n",
       "      <td>0.995627</td>\n",
       "      <td>0.998616</td>\n",
       "      <td>0.997517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.990576</td>\n",
       "      <td>0.990756</td>\n",
       "      <td>0.987907</td>\n",
       "      <td>0.991259</td>\n",
       "      <td>0.109791</td>\n",
       "      <td>0.997688</td>\n",
       "      <td>0.787126</td>\n",
       "      <td>0.988136</td>\n",
       "      <td>0.993112</td>\n",
       "      <td>0.997688</td>\n",
       "      <td>0.998180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.988426</td>\n",
       "      <td>0.990247</td>\n",
       "      <td>0.987931</td>\n",
       "      <td>0.991344</td>\n",
       "      <td>0.034258</td>\n",
       "      <td>0.996574</td>\n",
       "      <td>0.726133</td>\n",
       "      <td>0.989606</td>\n",
       "      <td>0.989602</td>\n",
       "      <td>0.996574</td>\n",
       "      <td>0.999461</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       open      high       low     close    volume     sma20      macd  \\\n",
       "0  1.000000  1.000000  1.000000  0.999972  0.030238  1.000000  1.000000   \n",
       "1  0.997085  0.997032  0.999304  1.000000  0.055791  0.999248  0.923749   \n",
       "2  0.997114  0.996268  0.992994  0.997190  0.051974  0.998616  0.852897   \n",
       "3  0.990576  0.990756  0.987907  0.991259  0.109791  0.997688  0.787126   \n",
       "4  0.988426  0.990247  0.987931  0.991344  0.034258  0.996574  0.726133   \n",
       "\n",
       "        obv  bb20_low  bb20_mid   bb20_up  \n",
       "0  0.992558  1.000000  1.000000  0.995914  \n",
       "1  0.994914  0.997594  0.999248  0.996815  \n",
       "2  0.992716  0.995627  0.998616  0.997517  \n",
       "3  0.988136  0.993112  0.997688  0.998180  \n",
       "4  0.989606  0.989602  0.996574  0.999461  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# Parameters\n",
    "params = {'batch_size': 64,\n",
    "          'shuffle': True,\n",
    "          'num_workers': 5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _train(train_gen, model, optim, error_func):\n",
    "    losses = []\n",
    "    \n",
    "    for batch, labels in train_gen:    \n",
    "        batch, labels = batch.cuda().float(), labels.cuda().float()\n",
    "        # set model to train mode\n",
    "        model.train()\n",
    "        \n",
    "        # clear gradients\n",
    "        model.zero_grad()\n",
    "        \n",
    "        output = model(batch)\n",
    "        loss = error_func(output, labels)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        \n",
    "        \n",
    "        losses.append(loss)\n",
    "        \n",
    "    return round(float(sum(losses) / len(losses)), 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _valid(valid_gen, model, optim, error_func):\n",
    "    with torch.set_grad_enabled(False):\n",
    "        losses = []\n",
    "\n",
    "        for batch, labels in valid_gen:\n",
    "            batch, labels = batch.cuda().float(), labels.cuda().float()\n",
    "            \n",
    "            # set to eval mode\n",
    "            model.eval()\n",
    "            \n",
    "            # clear gradients\n",
    "            model.zero_grad()\n",
    "\n",
    "            output = model(batch)\n",
    "            loss = error_func(output, labels)\n",
    "\n",
    "            losses.append(loss)\n",
    "        \n",
    "    return round(float(sum(losses) / len(losses)), 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _test(test_gen, model, optim, error_func):\n",
    "    with torch.set_grad_enabled(False):\n",
    "        losses = []\n",
    "\n",
    "        for batch, labels in valid_gen:\n",
    "            batch, labels = batch.cuda().float(), labels.cuda().float()\n",
    "            \n",
    "            # set to eval mode\n",
    "            model.eval()\n",
    "            \n",
    "            # clear gradients\n",
    "            model.zero_grad()\n",
    "\n",
    "            output = model(batch)\n",
    "            loss = error_func(output, labels)\n",
    "\n",
    "            losses.append(loss)\n",
    "        \n",
    "    return round(float(sum(losses) / len(losses)), 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, model_name, optim, num_epochs, train_gen, valid_gen, test_gen=None):\n",
    "    \"\"\"Train a PyTorch model with optim as optimizer strategy\"\"\"\n",
    "    \n",
    "    for epoch_i in range(num_epochs):\n",
    "        \n",
    "        \n",
    "        def RMSE(x, y):\n",
    "            \n",
    "            # have to squish x into a rank 1 tensor with batch_size length with the outputs we want\n",
    "            if model_name == 'resnet':\n",
    "                 # torch.Size([64, 1])\n",
    "                x = x.squeeze(1)\n",
    "            elif model_name == 'gru':\n",
    "                # torch.Size([64, 30, 1])\n",
    "                x = x[:, 29, :] # take only the last prediction from the 30 time periods in our matrix\n",
    "                x = x.squeeze(1)\n",
    "    \n",
    "            mse = torch.nn.MSELoss()\n",
    "            return torch.sqrt(mse(x, y))\n",
    "        \n",
    "        \n",
    "        # forward and backward passes of all batches inside train_gen\n",
    "        train_loss = _train(train_gen, model, optim, RMSE)\n",
    "        valid_loss = _valid(valid_gen, model, optim, RMSE)\n",
    "        \n",
    "        # run on test set if provided\n",
    "        if test_gen: test_output = _test(test_gen, model, optim)\n",
    "        else: test_output = \"no test selected\"\n",
    "        print(\"train loss: {}, valid loss: {}, test output: {}\".format(train_loss, valid_loss, test_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.CNN.CNN import CNN\n",
    "cnn = CNN().cuda().float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.datasets import DFTimeSeriesDataset, ChartImageDataset\n",
    "from torch.utils.data import *\n",
    "# create dataloaders\n",
    "# specify the split between train_df and valid_df from the process of splitting dataset_windows \n",
    "split = 0.7\n",
    "\n",
    "s = int(len(candles_sliced) * 0.7)\n",
    "while s % params['batch_size'] != 0:\n",
    "    s += 1\n",
    "\n",
    "# create two ChartImageDatasets, split by split, for the purpose of creating a DataLoader for the specific model\n",
    "train_ds_cnn = ChartImageDataset(paths_to_images[:s], price_returnz[:s])\n",
    "valid_ds_cnn = ChartImageDataset(paths_to_images[s:], price_returnz[s:])\n",
    "train_gen_cnn = DataLoader(train_ds_cnn, **params)\n",
    "valid_gen_cnn = DataLoader(valid_ds_cnn, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(cnn, 'resnet', torch.optim.Adam(cnn.parameters(), 1e-3), 8, train_gen_cnn, valid_gen_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(cnn, 'cnn_weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.GRU.GRU import GRUnet\n",
    "gru = GRUnet(num_features=11, num_rows=30, batch_size=64, hidden_size=50, num_layers=5).cuda().float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.datasets import DFTimeSeriesDataset, ChartImageDataset\n",
    "from torch.utils.data import *\n",
    "# create dataloaders\n",
    "# specify the split between train_df and valid_df from the process of splitting dataset_windows \n",
    "split = 0.7\n",
    "\n",
    "s = int(len(candles_sliced) * 0.7)\n",
    "while s % params['batch_size'] != 0:\n",
    "    s += 1\n",
    "print(s)\n",
    "\n",
    "# create two ChartImageDatasets, split by split, for the purpose of creating a DataLoader for the specific model\n",
    "train_ds_gru = DFTimeSeriesDataset(candles_sliced[:s], price_returnz[:s])\n",
    "valid_ds_gru = DFTimeSeriesDataset(candles_sliced[s:], price_returnz[s:])\n",
    "train_gen_gru = DataLoader(train_ds_gru, **params, drop_last=True)\n",
    "valid_gen_gru = DataLoader(valid_ds_gru, **params, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(gru, 'gru', torch.optim.Adam(gru.parameters(), 1e-3), 10, train_gen_gru, valid_gen_gru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.saving_models import save_model, load_model\n",
    "\n",
    "save_model(gru, 'gru_weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from BackTest import BackTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bw = BinanceWrapper('5lJ0uGit9PuUxHka3hBWhPmsi7dWyxEwvEntUZFKmm0xfNz3VjHWi5WSr5W1VBJV','BFWVs8ko7Cd4sjdQ9amGJTnToGWy9TbQWIjeorSCj23FGiwFaknzkgLPcrgWrxsw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.GRU.GRU import GRUnet\n",
    "gru = GRUnet(num_features=11, num_rows=30, batch_size=1, hidden_size=50, num_layers=5, eval_mode=False).float().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = CNN().cuda().float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.saving_models import load_model\n",
    "load_model(gru, 'gru_weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from strategies.example_strategies import RNNStrat\n",
    "strat = RNNStrat(gru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = BackTest(bw, strat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0\n",
      "torch.Size([1, 30, 11])\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'curr_prices' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-4dfb3c35d1dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofit_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gru\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Projects/FALKOR/BackTest.py\u001b[0m in \u001b[0;36mprofit_test\u001b[0;34m(self, candles_df, model_type)\u001b[0m\n\u001b[1;32m     81\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mmodel_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"gru\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m                         \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDFTimeSeriesDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit_candles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfut_prices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0;34m\"{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgekko\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbacktest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Projects/FALKOR/Gekko.py\u001b[0m in \u001b[0;36mbacktest\u001b[0;34m(self, strategy, dataset, model_name)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m                 \u001b[0mmoney\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mcurr_prices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m                 \u001b[0mmoney\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mfut_prices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'curr_prices' is not defined"
     ]
    }
   ],
   "source": [
    "b.profit_test(candles, model_type=\"gru\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
