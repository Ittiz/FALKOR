{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.charting_tools import Charting\n",
    "from helpers.data_processing import add_ti\n",
    "from BookWorm import BookWorm, BinanceWrapper\n",
    "from PIL import Image\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "worm = BookWorm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "candles = worm.historical_candles(start_time='January 1 2017', end_time='January 1 2019', api_wrapper=BinanceWrapper('5lJ0uGit9PuUxHka3hBWhPmsi7dWyxEwvEntUZFKmm0xfNz3VjHWi5WSr5W1VBJV',\n",
    "                                                      'BFWVs8ko7Cd4sjdQ9amGJTnToGWy9TbQWIjeorSCj23FGiwFaknzkgLPcrgWrxsw'), \n",
    "                  symbol='ETHBTC', interval='1m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "candles = worm.historical_candles(start_time='February 2 2018', end_time='August 1 2018', api_wrapper=BinanceWrapper('5lJ0uGit9PuUxHka3hBWhPmsi7dWyxEwvEntUZFKmm0xfNz3VjHWi5WSr5W1VBJV',\n",
    "                                                      'BFWVs8ko7Cd4sjdQ9amGJTnToGWy9TbQWIjeorSCj23FGiwFaknzkgLPcrgWrxsw'), \n",
    "                  symbol='ETHBTC', interval='1m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "candles.to_csv('ethbtc_2yr.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "candles = pd.read_csv('ethbtc_2yr.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "candles = add_ti(candles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_candles(df, num_rows=30, step=10):\n",
    "    \"\"\"Split a DataFrame of candlestick data into a list of smaller DataFrames each with num_rows rows\"\"\"\n",
    "    \n",
    "    slices = []\n",
    "    \n",
    "    for row_i in range(0, df.shape[0] - num_rows, step):\n",
    "        small_df = df.iloc[row_i:row_i+num_rows, :]\n",
    "        slices.append(small_df)\n",
    "        \n",
    "    return slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def price_returns(df, num_rows=30, num_into_fut=5, step=10):\n",
    "    labels = []\n",
    "    \n",
    "    for row_i in range(0, df.shape[0] - num_rows - num_into_fut, step):\n",
    "        # skip all iterations while row_i < num_rows since nothing yet to create a label for\n",
    "        if row_i <= num_rows: continue\n",
    "        \n",
    "        vf, vi = df['close'][row_i+num_into_fut], df['close'][row_i]\n",
    "        price_return = (vf - vi) / vi\n",
    "        labels.append(price_return)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_charts(candles_sliced, save_path):\n",
    "    \"\"\"Create a chart image for each in sliced_candles and return a list of paths to those images\"\"\"\n",
    "    from tqdm import tqdm_notebook as tqdm\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    \n",
    "    i = 0\n",
    "    paths_to_images = []\n",
    "    for small_df in tqdm(candles_sliced):\n",
    "        chart = Charting(small_df, 'time', 'close')\n",
    "        \n",
    "        path = save_path + 'chart_{}.png'.format(i)\n",
    "        chart.chart_to_image(path)\n",
    "        paths_to_images.append(path)\n",
    "        i += 1\n",
    "    return paths_to_images        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_to_images = create_charts(candles_sliced, \"images/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_to_images = [ 'images/chart_{}.png'.format(i) for i in range(len(candles_sliced)) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.open(paths_to_images[103])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_returnz = price_returns(candles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_series(ser):\n",
    "    return (ser-ser.min())/(ser.max()-ser.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(767705, 11)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try: candles = candles.drop('time', axis=1).reset_index(drop=True)\n",
    "except: pass\n",
    "candles.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(767705, 11)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candles = candles.apply(normalize_series, axis=0)\n",
    "candles.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76763"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split candles into 30 period and a label\n",
    "candles_sliced = split_candles(candles)\n",
    "# we need to remove candle slices without a label from candles_sliced\n",
    "candles_sliced = candles_sliced[len(candles_sliced)-len(price_returnz):]\n",
    "\n",
    "assert len(candles_sliced) == len(price_returnz)\n",
    "len(candles_sliced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>sma20</th>\n",
       "      <th>macd</th>\n",
       "      <th>obv</th>\n",
       "      <th>bb20_low</th>\n",
       "      <th>bb20_mid</th>\n",
       "      <th>bb20_up</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.625265</td>\n",
       "      <td>0.624317</td>\n",
       "      <td>0.626416</td>\n",
       "      <td>0.625295</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>0.607249</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.483798</td>\n",
       "      <td>0.556625</td>\n",
       "      <td>0.607249</td>\n",
       "      <td>0.651261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.617806</td>\n",
       "      <td>0.616862</td>\n",
       "      <td>0.618944</td>\n",
       "      <td>0.617836</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.610275</td>\n",
       "      <td>0.939988</td>\n",
       "      <td>0.483798</td>\n",
       "      <td>0.561115</td>\n",
       "      <td>0.610275</td>\n",
       "      <td>0.652808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.617955</td>\n",
       "      <td>0.618671</td>\n",
       "      <td>0.619094</td>\n",
       "      <td>0.619646</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.612922</td>\n",
       "      <td>0.884244</td>\n",
       "      <td>0.483801</td>\n",
       "      <td>0.566401</td>\n",
       "      <td>0.612922</td>\n",
       "      <td>0.652828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.619616</td>\n",
       "      <td>0.618671</td>\n",
       "      <td>0.620757</td>\n",
       "      <td>0.619646</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.615661</td>\n",
       "      <td>0.832495</td>\n",
       "      <td>0.483801</td>\n",
       "      <td>0.572414</td>\n",
       "      <td>0.615661</td>\n",
       "      <td>0.652317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.619616</td>\n",
       "      <td>0.618671</td>\n",
       "      <td>0.620757</td>\n",
       "      <td>0.619646</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.618400</td>\n",
       "      <td>0.784494</td>\n",
       "      <td>0.483801</td>\n",
       "      <td>0.579323</td>\n",
       "      <td>0.618400</td>\n",
       "      <td>0.650924</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       open      high       low     close    volume     sma20      macd  \\\n",
       "0  0.625265  0.624317  0.626416  0.625295  0.000153  0.607249  1.000000   \n",
       "1  0.617806  0.616862  0.618944  0.617836  0.000004  0.610275  0.939988   \n",
       "2  0.617955  0.618671  0.619094  0.619646  0.000076  0.612922  0.884244   \n",
       "3  0.619616  0.618671  0.620757  0.619646  0.000010  0.615661  0.832495   \n",
       "4  0.619616  0.618671  0.620757  0.619646  0.000000  0.618400  0.784494   \n",
       "\n",
       "        obv  bb20_low  bb20_mid   bb20_up  \n",
       "0  0.483798  0.556625  0.607249  0.651261  \n",
       "1  0.483798  0.561115  0.610275  0.652808  \n",
       "2  0.483801  0.566401  0.612922  0.652828  \n",
       "3  0.483801  0.572414  0.615661  0.652317  \n",
       "4  0.483801  0.579323  0.618400  0.650924  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# Parameters\n",
    "params = {'batch_size': 64,\n",
    "          'shuffle': True,\n",
    "          'num_workers': 5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _train(train_gen, model, optim, error_func):\n",
    "    losses = []\n",
    "    \n",
    "    for batch, labels in train_gen:    \n",
    "        batch, labels = batch.cuda().float(), labels.cuda().float()\n",
    "        # set model to train mode\n",
    "        model.train()\n",
    "        \n",
    "        # clear gradients\n",
    "        model.zero_grad()\n",
    "        \n",
    "        output = model(batch)\n",
    "        loss = error_func(output, labels)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        \n",
    "        \n",
    "        losses.append(loss)\n",
    "        \n",
    "    return round(float(sum(losses) / len(losses)), 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _valid(valid_gen, model, optim, error_func):\n",
    "    with torch.set_grad_enabled(False):\n",
    "        losses = []\n",
    "\n",
    "        for batch, labels in valid_gen:\n",
    "            batch, labels = batch.cuda().float(), labels.cuda().float()\n",
    "            \n",
    "            # set to eval mode\n",
    "            model.eval()\n",
    "            \n",
    "            # clear gradients\n",
    "            model.zero_grad()\n",
    "\n",
    "            output = model(batch)\n",
    "            loss = error_func(output, labels)\n",
    "\n",
    "            losses.append(loss)\n",
    "        \n",
    "    return round(float(sum(losses) / len(losses)), 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _test(test_gen, model, optim, error_func):\n",
    "    with torch.set_grad_enabled(False):\n",
    "        losses = []\n",
    "\n",
    "        for batch, labels in valid_gen:\n",
    "            batch, labels = batch.cuda().float(), labels.cuda().float()\n",
    "            \n",
    "            # set to eval mode\n",
    "            model.eval()\n",
    "            \n",
    "            # clear gradients\n",
    "            model.zero_grad()\n",
    "\n",
    "            output = model(batch)\n",
    "            loss = error_func(output, labels)\n",
    "\n",
    "            losses.append(loss)\n",
    "        \n",
    "    return round(float(sum(losses) / len(losses)), 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, model_name, optim, num_epochs, train_gen, valid_gen, test_gen=None):\n",
    "    \"\"\"Train a PyTorch model with optim as optimizer strategy\"\"\"\n",
    "    \n",
    "    for epoch_i in range(num_epochs):\n",
    "        \n",
    "        \n",
    "        def RMSE(x, y):\n",
    "            \n",
    "            # have to squish x into a rank 1 tensor with batch_size length with the outputs we want\n",
    "            if model_name == 'resnet':\n",
    "                 # torch.Size([64, 1])\n",
    "                x = x.squeeze(1)\n",
    "            elif model_name == 'gru':\n",
    "                # torch.Size([64, 30, 1])\n",
    "                x = x[:, 29, :] # take only the last prediction from the 30 time periods in our matrix\n",
    "                x = x.squeeze(1)\n",
    "    \n",
    "            mse = torch.nn.MSELoss()\n",
    "            return torch.sqrt(mse(x, y))\n",
    "        \n",
    "        \n",
    "        # forward and backward passes of all batches inside train_gen\n",
    "        train_loss = _train(train_gen, model, optim, RMSE)\n",
    "        valid_loss = _valid(valid_gen, model, optim, RMSE)\n",
    "        \n",
    "        # run on test set if provided\n",
    "        if test_gen: test_output = _test(test_gen, model, optim)\n",
    "        else: test_output = \"no test selected\"\n",
    "        print(\"train loss: {}, valid loss: {}, test output: {}\".format(train_loss, valid_loss, test_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.CNN.CNN import CNN\n",
    "cnn = CNN().cuda().float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.datasets import DFTimeSeriesDataset, ChartImageDataset\n",
    "from torch.utils.data import *\n",
    "# create dataloaders\n",
    "# specify the split between train_df and valid_df from the process of splitting dataset_windows \n",
    "split = 0.7\n",
    "\n",
    "s = int(len(candles_sliced) * 0.7)\n",
    "while s % params['batch_size'] != 0:\n",
    "    s += 1\n",
    "\n",
    "# create two ChartImageDatasets, split by split, for the purpose of creating a DataLoader for the specific model\n",
    "train_ds_cnn = ChartImageDataset(paths_to_images[:s], price_returnz[:s])\n",
    "valid_ds_cnn = ChartImageDataset(paths_to_images[s:], price_returnz[s:])\n",
    "train_gen_cnn = DataLoader(train_ds_cnn, **params)\n",
    "valid_gen_cnn = DataLoader(valid_ds_cnn, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(cnn, 'resnet', torch.optim.Adam(cnn.parameters(), 1e-3), 8, train_gen_cnn, valid_gen_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(cnn, 'cnn_weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.GRU.GRU import GRUnet\n",
    "gru = GRUnet(num_features=11, num_rows=30, batch_size=64, hidden_size=500, num_layers=5).cuda().float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53760\n"
     ]
    }
   ],
   "source": [
    "from helpers.datasets import DFTimeSeriesDataset, ChartImageDataset\n",
    "from torch.utils.data import *\n",
    "# create dataloaders\n",
    "# specify the split between train_df and valid_df from the process of splitting dataset_windows \n",
    "split = 0.7\n",
    "\n",
    "s = int(len(candles_sliced) * 0.7)\n",
    "while s % params['batch_size'] != 0:\n",
    "    s += 1\n",
    "print(s)\n",
    "\n",
    "# create two ChartImageDatasets, split by split, for the purpose of creating a DataLoader for the specific model\n",
    "train_ds_gru = DFTimeSeriesDataset(candles_sliced[:s], price_returnz[:s])\n",
    "valid_ds_gru = DFTimeSeriesDataset(candles_sliced[s:], price_returnz[s:])\n",
    "train_gen_gru = DataLoader(train_ds_gru, **params, drop_last=True)\n",
    "valid_gen_gru = DataLoader(valid_ds_gru, **params, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.014936, valid loss: 0.001772, test output: no test selected\n",
      "train loss: 0.003143, valid loss: 0.001772, test output: no test selected\n",
      "train loss: 0.003155, valid loss: 0.001874, test output: no test selected\n",
      "train loss: 0.003137, valid loss: 0.001763, test output: no test selected\n",
      "train loss: 0.003133, valid loss: 0.002392, test output: no test selected\n",
      "train loss: 0.003079, valid loss: 0.001894, test output: no test selected\n",
      "train loss: 0.003134, valid loss: 0.001755, test output: no test selected\n",
      "train loss: 0.003136, valid loss: 0.002049, test output: no test selected\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-350a6b695218>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgru\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'gru'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgru\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1e-2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_gen_gru\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_gen_gru\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-28-618687678144>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, model_name, optim, num_epochs, train_gen, valid_gen, test_gen)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m# forward and backward passes of all batches inside train_gen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRMSE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mvalid_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_valid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRMSE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m# run on test set if provided\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-586ed048a5eb>\u001b[0m in \u001b[0;36m_valid\u001b[0;34m(valid_gen, model, optim, error_func)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-28-618687678144>\u001b[0m in \u001b[0;36mRMSE\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMSELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 431\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mmse_loss\u001b[0;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   2188\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2189\u001b[0m         \u001b[0mexpanded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2190\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpanded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2191\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(gru, 'gru', torch.optim.Adam(gru.parameters(), 1e-2), 15, train_gen_gru, valid_gen_gru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.saving_models import save_model, load_model\n",
    "\n",
    "save_model(gru, 'gru_weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from BackTest import BackTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bw = BinanceWrapper('5lJ0uGit9PuUxHka3hBWhPmsi7dWyxEwvEntUZFKmm0xfNz3VjHWi5WSr5W1VBJV','BFWVs8ko7Cd4sjdQ9amGJTnToGWy9TbQWIjeorSCj23FGiwFaknzkgLPcrgWrxsw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.GRU.GRU import GRUnet\n",
    "gru = GRUnet(num_features=11, num_rows=30, batch_size=1, hidden_size=50, num_layers=5, eval_mode=False).float().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = CNN().cuda().float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.saving_models import load_model\n",
    "load_model(gru, 'gru_weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from strategies.example_strategies import RNNStrat\n",
    "strat = RNNStrat(gru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = BackTest(bw, strat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.profit_test(candles, model_type=\"gru\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
